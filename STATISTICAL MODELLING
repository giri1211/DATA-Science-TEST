import pandas as pd
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

boston = load_boston()
data = pd.DataFrame(boston.data, columns=boston.feature_names)
data['PRICE'] = boston.target

print(data.head())

X = data.drop('PRICE', axis=1)
y = data['PRICE']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()

numerical_pipeline = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),  # Handle missing values
    ('scaler', StandardScaler())  # Scale numerical features
])


preprocessor = ColumnTransformer(
    transformers=[
        ('num', numerical_pipeline, numerical_features)
    ])

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

models = {
    'Linear Regression': LinearRegression(),
    'Ridge Regression': Ridge(alpha=1.0),
    'Lasso Regression': Lasso(alpha=0.1)
}

results = {}
for name, model in models.items():
    model.fit(X_train_processed, y_train)
    y_pred = model.predict(X_test_processed)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    results[name] = {'RMSE': rmse, 'R2': r2}

print(results)

from sklearn.model_selection import cross_val_score
for name, model in models.items():
    scores = cross_val_score(model, X_train_processed, y_train, cv=5, scoring='neg_mean_squared_error')
    rmse_scores = np.sqrt(-scores)
    print(f"{name} - Cross-validated RMSE: {rmse_scores.mean()} Â± {rmse_scores.std()}")


import matplotlib.pyplot as plt

best_model = models['Linear Regression']
y_pred = best_model.predict(X_test_processed)
residuals = y_test - y_pred

plt.scatter(y_pred, residuals)
plt.axhline(y=0, color='r', linestyle='--')
plt.xlabel('Predicted Values')
plt.ylabel('Residuals')
plt.title('Residual Plot')
plt.show()

from sklearn.model_selection import GridSearchCV

param_grid_ridge = {'alpha': [0.1, 1.0, 10.0]}
param_grid_lasso = {'alpha': [0.01, 0.1, 1.0]}

grid_ridge = GridSearchCV(Ridge(), param_grid_ridge, cv=5, scoring='neg_mean_squared_error')
grid_lasso = GridSearchCV(Lasso(), param_grid_lasso, cv=5, scoring='neg_mean_squared_error')

grid_ridge.fit(X_train_processed, y_train)
grid_lasso.fit(X_train_processed, y_train)

print(f"Best Ridge parameters: {grid_ridge.best_params_}")
print(f"Best Lasso parameters: {grid_lasso.best_params_}")

best_ridge = grid_ridge.best_estimator_
best_lasso = grid_lasso.best_estimator_

y_pred_ridge = best_ridge.predict(X_test_processed)
y_pred_lasso = best_lasso.predict(X_test_processed)

print(f"Ridge Regression RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_ridge))}")
print(f"Lasso Regression RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_lasso))}")

coef_ridge = pd.Series(best_ridge.coef_, index=numerical_features)
coef_lasso = pd.Series(best_lasso.coef_, index=numerical_features)

print("Ridge Regression Coefficients:")
print(coef_ridge.sort_values(ascending=False))

print("Lasso Regression Coefficients:")
print(coef_lasso.sort_values(ascending=False))



